{
    "STEM": {
        "physics": {
            "astronomy": {
                "Accuracy": 0.3092105263157895
            },
            "college_physics": {
                "Accuracy": 0.14705882352941177
            },
            "conceptual_physics": {
                "Accuracy": 0.33191489361702126
            },
            "high_school_physics": {
                "Accuracy": 0.3509933774834437
            },
            "average": {
                "Accuracy": 0.2847944052364166
            },
            "overall": {
                "Accuracy": 0.3015625
            }
        },
        "chemistry": {
            "college_chemistry": {
                "Accuracy": 0.36
            },
            "high_school_chemistry": {
                "Accuracy": 0.3251231527093596
            },
            "average": {
                "Accuracy": 0.34256157635467976
            },
            "overall": {
                "Accuracy": 0.33663366336633666
            }
        },
        "biology": {
            "college_biology": {
                "Accuracy": 0.2708333333333333
            },
            "high_school_biology": {
                "Accuracy": 0.27419354838709675
            },
            "average": {
                "Accuracy": 0.272513440860215
            },
            "overall": {
                "Accuracy": 0.27312775330396477
            }
        },
        "computer science": {
            "college_computer_science": {
                "Accuracy": 0.32
            },
            "computer_security": {
                "Accuracy": 0.3
            },
            "high_school_computer_science": {
                "Accuracy": 0.24
            },
            "machine_learning": {
                "Accuracy": 0.26785714285714285
            },
            "average": {
                "Accuracy": 0.2819642857142857
            },
            "overall": {
                "Accuracy": 0.2815533980582524
            }
        },
        "math": {
            "abstract_algebra": {
                "Accuracy": 0.25
            },
            "college_mathematics": {
                "Accuracy": 0.34
            },
            "elementary_mathematics": {
                "Accuracy": 0.2619047619047619
            },
            "high_school_mathematics": {
                "Accuracy": 0.2777777777777778
            },
            "high_school_statistics": {
                "Accuracy": 0.4305555555555556
            },
            "average": {
                "Accuracy": 0.3120476190476191
            },
            "overall": {
                "Accuracy": 0.30639097744360905
            }
        },
        "engineering": {
            "electrical_engineering": {
                "Accuracy": 0.32413793103448274
            },
            "average": {
                "Accuracy": 0.32413793103448274
            },
            "overall": {
                "Accuracy": 0.32413793103448274
            }
        }
    },
    "humanities": {
        "history": {
            "high_school_european_history": {
                "Accuracy": 0.24242424242424243
            },
            "high_school_us_history": {
                "Accuracy": 0.25980392156862747
            },
            "high_school_world_history": {
                "Accuracy": 0.29957805907172996
            },
            "prehistory": {
                "Accuracy": 0.2654320987654321
            },
            "average": {
                "Accuracy": 0.26680958045750797
            },
            "overall": {
                "Accuracy": 0.26881720430107525
            }
        },
        "philosophy": {
            "formal_logic": {
                "Accuracy": 0.3253968253968254
            },
            "logical_fallacies": {
                "Accuracy": 0.27607361963190186
            },
            "moral_disputes": {
                "Accuracy": 0.2861271676300578
            },
            "moral_scenarios": {
                "Accuracy": 0.24804469273743016
            },
            "philosophy": {
                "Accuracy": 0.31511254019292606
            },
            "world_religions": {
                "Accuracy": 0.3216374269005848
            },
            "average": {
                "Accuracy": 0.295398712081621
            },
            "overall": {
                "Accuracy": 0.2783300198807157
            }
        },
        "law": {
            "international_law": {
                "Accuracy": 0.4462809917355372
            },
            "jurisprudence": {
                "Accuracy": 0.3425925925925926
            },
            "professional_law": {
                "Accuracy": 0.16427640156453716
            },
            "average": {
                "Accuracy": 0.3177166619642223
            },
            "overall": {
                "Accuracy": 0.19455473624503686
            }
        }
    },
    "social sciences": {
        "politics": {
            "high_school_government_and_politics": {
                "Accuracy": 0.33678756476683935
            },
            "public_relations": {
                "Accuracy": 0.3090909090909091
            },
            "security_studies": {
                "Accuracy": 0.2693877551020408
            },
            "us_foreign_policy": {
                "Accuracy": 0.28
            },
            "average": {
                "Accuracy": 0.2988165572399473
            },
            "overall": {
                "Accuracy": 0.2978395061728395
            }
        },
        "culture": {
            "human_sexuality": {
                "Accuracy": 0.2595419847328244
            },
            "sociology": {
                "Accuracy": 0.30845771144278605
            },
            "average": {
                "Accuracy": 0.2839998480878052
            },
            "overall": {
                "Accuracy": 0.2891566265060241
            }
        },
        "economics": {
            "econometrics": {
                "Accuracy": 0.20175438596491227
            },
            "high_school_macroeconomics": {
                "Accuracy": 0.3333333333333333
            },
            "high_school_microeconomics": {
                "Accuracy": 0.2815126050420168
            },
            "average": {
                "Accuracy": 0.2722001081134208
            },
            "overall": {
                "Accuracy": 0.29649595687331537
            }
        },
        "geography": {
            "high_school_geography": {
                "Accuracy": 0.2676767676767677
            },
            "average": {
                "Accuracy": 0.2676767676767677
            },
            "overall": {
                "Accuracy": 0.2676767676767677
            }
        },
        "psychology": {
            "high_school_psychology": {
                "Accuracy": 0.27522935779816515
            },
            "professional_psychology": {
                "Accuracy": 0.22549019607843138
            },
            "average": {
                "Accuracy": 0.25035977693829825
            },
            "overall": {
                "Accuracy": 0.24891961970613655
            }
        }
    },
    "other (business, health, misc.)": {
        "other": {
            "global_facts": {
                "Accuracy": 0.32
            },
            "miscellaneous": {
                "Accuracy": 0.29118773946360155
            },
            "professional_accounting": {
                "Accuracy": 0.29432624113475175
            },
            "average": {
                "Accuracy": 0.30183799353278445
            },
            "overall": {
                "Accuracy": 0.2944206008583691
            }
        },
        "business": {
            "business_ethics": {
                "Accuracy": 0.32
            },
            "management": {
                "Accuracy": 0.3106796116504854
            },
            "marketing": {
                "Accuracy": 0.32905982905982906
            },
            "average": {
                "Accuracy": 0.31991314690343814
            },
            "overall": {
                "Accuracy": 0.32265446224256294
            }
        },
        "health": {
            "anatomy": {
                "Accuracy": 0.23703703703703705
            },
            "clinical_knowledge": {
                "Accuracy": 0.30566037735849055
            },
            "college_medicine": {
                "Accuracy": 0.2543352601156069
            },
            "human_aging": {
                "Accuracy": 0.3273542600896861
            },
            "medical_genetics": {
                "Accuracy": 0.22
            },
            "nutrition": {
                "Accuracy": 0.3464052287581699
            },
            "professional_medicine": {
                "Accuracy": 0.4338235294117647
            },
            "virology": {
                "Accuracy": 0.2891566265060241
            },
            "average": {
                "Accuracy": 0.30172153990959744
            },
            "overall": {
                "Accuracy": 0.3195121951219512
            }
        }
    }
}
