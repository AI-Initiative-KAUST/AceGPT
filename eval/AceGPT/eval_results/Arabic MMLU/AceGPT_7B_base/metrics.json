{
    "STEM": {
        "physics": {
            "astronomy": {
                "Accuracy": 0.3223684210526316
            },
            "college_physics": {
                "Accuracy": 0.17647058823529413
            },
            "conceptual_physics": {
                "Accuracy": 0.31063829787234043
            },
            "high_school_physics": {
                "Accuracy": 0.2781456953642384
            },
            "average": {
                "Accuracy": 0.2719057506311261
            },
            "overall": {
                "Accuracy": 0.284375
            }
        },
        "chemistry": {
            "college_chemistry": {
                "Accuracy": 0.18
            },
            "high_school_chemistry": {
                "Accuracy": 0.2561576354679803
            },
            "average": {
                "Accuracy": 0.21807881773399015
            },
            "overall": {
                "Accuracy": 0.23102310231023102
            }
        },
        "biology": {
            "college_biology": {
                "Accuracy": 0.2708333333333333
            },
            "high_school_biology": {
                "Accuracy": 0.2903225806451613
            },
            "average": {
                "Accuracy": 0.2805779569892473
            },
            "overall": {
                "Accuracy": 0.2841409691629956
            }
        },
        "computer science": {
            "college_computer_science": {
                "Accuracy": 0.24
            },
            "computer_security": {
                "Accuracy": 0.39
            },
            "high_school_computer_science": {
                "Accuracy": 0.33
            },
            "machine_learning": {
                "Accuracy": 0.2767857142857143
            },
            "average": {
                "Accuracy": 0.3091964285714286
            },
            "overall": {
                "Accuracy": 0.308252427184466
            }
        },
        "math": {
            "abstract_algebra": {
                "Accuracy": 0.33
            },
            "college_mathematics": {
                "Accuracy": 0.25
            },
            "elementary_mathematics": {
                "Accuracy": 0.2698412698412698
            },
            "high_school_mathematics": {
                "Accuracy": 0.3037037037037037
            },
            "high_school_statistics": {
                "Accuracy": 0.25462962962962965
            },
            "average": {
                "Accuracy": 0.2816349206349207
            },
            "overall": {
                "Accuracy": 0.2791353383458647
            }
        },
        "engineering": {
            "electrical_engineering": {
                "Accuracy": 0.4413793103448276
            },
            "average": {
                "Accuracy": 0.4413793103448276
            },
            "overall": {
                "Accuracy": 0.4413793103448276
            }
        }
    },
    "humanities": {
        "history": {
            "high_school_european_history": {
                "Accuracy": 0.24242424242424243
            },
            "high_school_us_history": {
                "Accuracy": 0.23039215686274508
            },
            "high_school_world_history": {
                "Accuracy": 0.27848101265822783
            },
            "prehistory": {
                "Accuracy": 0.38271604938271603
            },
            "average": {
                "Accuracy": 0.28350336533198284
            },
            "overall": {
                "Accuracy": 0.2978494623655914
            }
        },
        "philosophy": {
            "formal_logic": {
                "Accuracy": 0.23015873015873015
            },
            "logical_fallacies": {
                "Accuracy": 0.3067484662576687
            },
            "moral_disputes": {
                "Accuracy": 0.36416184971098264
            },
            "moral_scenarios": {
                "Accuracy": 0.2446927374301676
            },
            "philosophy": {
                "Accuracy": 0.37942122186495175
            },
            "world_religions": {
                "Accuracy": 0.3567251461988304
            },
            "average": {
                "Accuracy": 0.3136513586035552
            },
            "overall": {
                "Accuracy": 0.29970178926441354
            }
        },
        "law": {
            "international_law": {
                "Accuracy": 0.5041322314049587
            },
            "jurisprudence": {
                "Accuracy": 0.3611111111111111
            },
            "professional_law": {
                "Accuracy": 0.14928292046936115
            },
            "average": {
                "Accuracy": 0.3381754209951436
            },
            "overall": {
                "Accuracy": 0.1866137266023823
            }
        }
    },
    "social sciences": {
        "politics": {
            "high_school_government_and_politics": {
                "Accuracy": 0.40414507772020725
            },
            "public_relations": {
                "Accuracy": 0.32727272727272727
            },
            "security_studies": {
                "Accuracy": 0.17551020408163265
            },
            "us_foreign_policy": {
                "Accuracy": 0.5
            },
            "average": {
                "Accuracy": 0.35173200226864176
            },
            "overall": {
                "Accuracy": 0.3194444444444444
            }
        },
        "culture": {
            "human_sexuality": {
                "Accuracy": 0.35877862595419846
            },
            "sociology": {
                "Accuracy": 0.3781094527363184
            },
            "average": {
                "Accuracy": 0.36844403934525843
            },
            "overall": {
                "Accuracy": 0.3704819277108434
            }
        },
        "economics": {
            "econometrics": {
                "Accuracy": 0.34210526315789475
            },
            "high_school_macroeconomics": {
                "Accuracy": 0.33589743589743587
            },
            "high_school_microeconomics": {
                "Accuracy": 0.27310924369747897
            },
            "average": {
                "Accuracy": 0.31703731425093656
            },
            "overall": {
                "Accuracy": 0.316711590296496
            }
        },
        "geography": {
            "high_school_geography": {
                "Accuracy": 0.3282828282828283
            },
            "average": {
                "Accuracy": 0.3282828282828283
            },
            "overall": {
                "Accuracy": 0.3282828282828283
            }
        },
        "psychology": {
            "high_school_psychology": {
                "Accuracy": 0.3137614678899083
            },
            "professional_psychology": {
                "Accuracy": 0.2973856209150327
            },
            "average": {
                "Accuracy": 0.3055735444024705
            },
            "overall": {
                "Accuracy": 0.3050993949870354
            }
        }
    },
    "other (business, health, misc.)": {
        "other": {
            "global_facts": {
                "Accuracy": 0.25
            },
            "miscellaneous": {
                "Accuracy": 0.3946360153256705
            },
            "professional_accounting": {
                "Accuracy": 0.2978723404255319
            },
            "average": {
                "Accuracy": 0.31416945191706747
            },
            "overall": {
                "Accuracy": 0.3587982832618026
            }
        },
        "business": {
            "business_ethics": {
                "Accuracy": 0.42
            },
            "management": {
                "Accuracy": 0.2912621359223301
            },
            "marketing": {
                "Accuracy": 0.405982905982906
            },
            "average": {
                "Accuracy": 0.3724150139684121
            },
            "overall": {
                "Accuracy": 0.38215102974828374
            }
        },
        "health": {
            "anatomy": {
                "Accuracy": 0.35555555555555557
            },
            "clinical_knowledge": {
                "Accuracy": 0.33962264150943394
            },
            "college_medicine": {
                "Accuracy": 0.28901734104046245
            },
            "human_aging": {
                "Accuracy": 0.3273542600896861
            },
            "medical_genetics": {
                "Accuracy": 0.32
            },
            "nutrition": {
                "Accuracy": 0.37254901960784315
            },
            "professional_medicine": {
                "Accuracy": 0.4007352941176471
            },
            "virology": {
                "Accuracy": 0.3373493975903614
            },
            "average": {
                "Accuracy": 0.3427729386888737
            },
            "overall": {
                "Accuracy": 0.348780487804878
            }
        }
    }
}
