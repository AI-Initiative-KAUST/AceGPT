{
    "STEM": {
        "physics": {
            "astronomy": {
                "Accuracy": 0.4605263157894737
            },
            "college_physics": {
                "Accuracy": 0.22549019607843138
            },
            "conceptual_physics": {
                "Accuracy": 0.39574468085106385
            },
            "high_school_physics": {
                "Accuracy": 0.32450331125827814
            },
            "average": {
                "Accuracy": 0.3515661259943118
            },
            "overall": {
                "Accuracy": 0.3671875
            }
        },
        "chemistry": {
            "college_chemistry": {
                "Accuracy": 0.28
            },
            "high_school_chemistry": {
                "Accuracy": 0.3891625615763547
            },
            "average": {
                "Accuracy": 0.3345812807881774
            },
            "overall": {
                "Accuracy": 0.35313531353135313
            }
        },
        "biology": {
            "college_biology": {
                "Accuracy": 0.3125
            },
            "high_school_biology": {
                "Accuracy": 0.42258064516129035
            },
            "average": {
                "Accuracy": 0.3675403225806452
            },
            "overall": {
                "Accuracy": 0.3876651982378855
            }
        },
        "computer science": {
            "college_computer_science": {
                "Accuracy": 0.34
            },
            "computer_security": {
                "Accuracy": 0.46
            },
            "high_school_computer_science": {
                "Accuracy": 0.39
            },
            "machine_learning": {
                "Accuracy": 0.25
            },
            "average": {
                "Accuracy": 0.36
            },
            "overall": {
                "Accuracy": 0.3567961165048544
            }
        },
        "math": {
            "abstract_algebra": {
                "Accuracy": 0.3
            },
            "college_mathematics": {
                "Accuracy": 0.32
            },
            "elementary_mathematics": {
                "Accuracy": 0.30687830687830686
            },
            "high_school_mathematics": {
                "Accuracy": 0.26666666666666666
            },
            "high_school_statistics": {
                "Accuracy": 0.33796296296296297
            },
            "average": {
                "Accuracy": 0.3063015873015873
            },
            "overall": {
                "Accuracy": 0.30357142857142855
            }
        },
        "engineering": {
            "electrical_engineering": {
                "Accuracy": 0.47586206896551725
            },
            "average": {
                "Accuracy": 0.47586206896551725
            },
            "overall": {
                "Accuracy": 0.47586206896551725
            }
        }
    },
    "humanities": {
        "history": {
            "high_school_european_history": {
                "Accuracy": 0.21212121212121213
            },
            "high_school_us_history": {
                "Accuracy": 0.24509803921568626
            },
            "high_school_world_history": {
                "Accuracy": 0.3628691983122363
            },
            "prehistory": {
                "Accuracy": 0.39197530864197533
            },
            "average": {
                "Accuracy": 0.3030159395727775
            },
            "overall": {
                "Accuracy": 0.3204301075268817
            }
        },
        "philosophy": {
            "formal_logic": {
                "Accuracy": 0.2619047619047619
            },
            "logical_fallacies": {
                "Accuracy": 0.4601226993865031
            },
            "moral_disputes": {
                "Accuracy": 0.49421965317919075
            },
            "moral_scenarios": {
                "Accuracy": 0.24581005586592178
            },
            "philosophy": {
                "Accuracy": 0.49517684887459806
            },
            "world_religions": {
                "Accuracy": 0.42105263157894735
            },
            "average": {
                "Accuracy": 0.3963811084649871
            },
            "overall": {
                "Accuracy": 0.36033797216699803
            }
        },
        "law": {
            "international_law": {
                "Accuracy": 0.6776859504132231
            },
            "jurisprudence": {
                "Accuracy": 0.5185185185185185
            },
            "professional_law": {
                "Accuracy": 0.19230769230769232
            },
            "average": {
                "Accuracy": 0.4628373870798113
            },
            "overall": {
                "Accuracy": 0.24560408394781622
            }
        }
    },
    "social sciences": {
        "politics": {
            "high_school_government_and_politics": {
                "Accuracy": 0.5129533678756477
            },
            "public_relations": {
                "Accuracy": 0.45454545454545453
            },
            "security_studies": {
                "Accuracy": 0.30612244897959184
            },
            "us_foreign_policy": {
                "Accuracy": 0.62
            },
            "average": {
                "Accuracy": 0.4734053178501736
            },
            "overall": {
                "Accuracy": 0.44135802469135804
            }
        },
        "culture": {
            "human_sexuality": {
                "Accuracy": 0.5038167938931297
            },
            "sociology": {
                "Accuracy": 0.5174129353233831
            },
            "average": {
                "Accuracy": 0.5106148646082564
            },
            "overall": {
                "Accuracy": 0.5120481927710844
            }
        },
        "economics": {
            "econometrics": {
                "Accuracy": 0.21929824561403508
            },
            "high_school_macroeconomics": {
                "Accuracy": 0.43333333333333335
            },
            "high_school_microeconomics": {
                "Accuracy": 0.36134453781512604
            },
            "average": {
                "Accuracy": 0.3379920389208315
            },
            "overall": {
                "Accuracy": 0.37735849056603776
            }
        },
        "geography": {
            "high_school_geography": {
                "Accuracy": 0.4898989898989899
            },
            "average": {
                "Accuracy": 0.4898989898989899
            },
            "overall": {
                "Accuracy": 0.4898989898989899
            }
        },
        "psychology": {
            "high_school_psychology": {
                "Accuracy": 0.4036697247706422
            },
            "professional_psychology": {
                "Accuracy": 0.3480392156862745
            },
            "average": {
                "Accuracy": 0.37585447022845836
            },
            "overall": {
                "Accuracy": 0.3742437337942956
            }
        }
    },
    "other (business, health, misc.)": {
        "other": {
            "global_facts": {
                "Accuracy": 0.29
            },
            "miscellaneous": {
                "Accuracy": 0.45721583652618136
            },
            "professional_accounting": {
                "Accuracy": 0.3404255319148936
            },
            "average": {
                "Accuracy": 0.36254712281369167
            },
            "overall": {
                "Accuracy": 0.4145922746781116
            }
        },
        "business": {
            "business_ethics": {
                "Accuracy": 0.47
            },
            "management": {
                "Accuracy": 0.5242718446601942
            },
            "marketing": {
                "Accuracy": 0.5982905982905983
            },
            "average": {
                "Accuracy": 0.5308541476502642
            },
            "overall": {
                "Accuracy": 0.551487414187643
            }
        },
        "health": {
            "anatomy": {
                "Accuracy": 0.4
            },
            "clinical_knowledge": {
                "Accuracy": 0.4528301886792453
            },
            "college_medicine": {
                "Accuracy": 0.3236994219653179
            },
            "human_aging": {
                "Accuracy": 0.4080717488789238
            },
            "medical_genetics": {
                "Accuracy": 0.27
            },
            "nutrition": {
                "Accuracy": 0.477124183006536
            },
            "professional_medicine": {
                "Accuracy": 0.3713235294117647
            },
            "virology": {
                "Accuracy": 0.4036144578313253
            },
            "average": {
                "Accuracy": 0.38833294122163914
            },
            "overall": {
                "Accuracy": 0.4036585365853659
            }
        }
    }
}
