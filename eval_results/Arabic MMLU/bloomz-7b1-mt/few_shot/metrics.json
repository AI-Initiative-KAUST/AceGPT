{
    "STEM": {
        "physics": {
            "astronomy": {
                "Accuracy": 0.3684210526315789
            },
            "college_physics": {
                "Accuracy": 0.3137254901960784
            },
            "conceptual_physics": {
                "Accuracy": 0.3191489361702128
            },
            "high_school_physics": {
                "Accuracy": 0.2913907284768212
            },
            "average": {
                "Accuracy": 0.3231715518686728
            },
            "overall": {
                "Accuracy": 0.3234375
            }
        },
        "chemistry": {
            "college_chemistry": {
                "Accuracy": 0.39
            },
            "high_school_chemistry": {
                "Accuracy": 0.33004926108374383
            },
            "average": {
                "Accuracy": 0.36002463054187195
            },
            "overall": {
                "Accuracy": 0.34983498349834985
            }
        },
        "biology": {
            "college_biology": {
                "Accuracy": 0.3472222222222222
            },
            "high_school_biology": {
                "Accuracy": 0.3741935483870968
            },
            "average": {
                "Accuracy": 0.36070788530465947
            },
            "overall": {
                "Accuracy": 0.3656387665198238
            }
        },
        "computer science": {
            "college_computer_science": {
                "Accuracy": 0.3
            },
            "computer_security": {
                "Accuracy": 0.33
            },
            "high_school_computer_science": {
                "Accuracy": 0.39
            },
            "machine_learning": {
                "Accuracy": 0.21428571428571427
            },
            "average": {
                "Accuracy": 0.30857142857142855
            },
            "overall": {
                "Accuracy": 0.3058252427184466
            }
        },
        "math": {
            "abstract_algebra": {
                "Accuracy": 0.24
            },
            "college_mathematics": {
                "Accuracy": 0.31
            },
            "elementary_mathematics": {
                "Accuracy": 0.2751322751322751
            },
            "high_school_mathematics": {
                "Accuracy": 0.29259259259259257
            },
            "high_school_statistics": {
                "Accuracy": 0.4351851851851852
            },
            "average": {
                "Accuracy": 0.31058201058201057
            },
            "overall": {
                "Accuracy": 0.31203007518796994
            }
        },
        "engineering": {
            "electrical_engineering": {
                "Accuracy": 0.33793103448275863
            },
            "average": {
                "Accuracy": 0.33793103448275863
            },
            "overall": {
                "Accuracy": 0.33793103448275863
            }
        }
    },
    "humanities": {
        "history": {
            "high_school_european_history": {
                "Accuracy": 0.24242424242424243
            },
            "high_school_us_history": {
                "Accuracy": 0.23529411764705882
            },
            "high_school_world_history": {
                "Accuracy": 0.2911392405063291
            },
            "prehistory": {
                "Accuracy": 0.2993827160493827
            },
            "average": {
                "Accuracy": 0.2670600791567533
            },
            "overall": {
                "Accuracy": 0.2731182795698925
            }
        },
        "philosophy": {
            "formal_logic": {
                "Accuracy": 0.36507936507936506
            },
            "logical_fallacies": {
                "Accuracy": 0.34355828220858897
            },
            "moral_disputes": {
                "Accuracy": 0.2976878612716763
            },
            "moral_scenarios": {
                "Accuracy": 0.23798882681564246
            },
            "philosophy": {
                "Accuracy": 0.3215434083601286
            },
            "world_religions": {
                "Accuracy": 0.19298245614035087
            },
            "average": {
                "Accuracy": 0.2931400333126254
            },
            "overall": {
                "Accuracy": 0.2738568588469185
            }
        },
        "law": {
            "international_law": {
                "Accuracy": 0.35537190082644626
            },
            "jurisprudence": {
                "Accuracy": 0.3425925925925926
            },
            "professional_law": {
                "Accuracy": 0.25749674054758803
            },
            "average": {
                "Accuracy": 0.3184870779888756
            },
            "overall": {
                "Accuracy": 0.26942711287578
            }
        }
    },
    "social sciences": {
        "politics": {
            "high_school_government_and_politics": {
                "Accuracy": 0.37823834196891193
            },
            "public_relations": {
                "Accuracy": 0.37272727272727274
            },
            "security_studies": {
                "Accuracy": 0.34285714285714286
            },
            "us_foreign_policy": {
                "Accuracy": 0.34
            },
            "average": {
                "Accuracy": 0.3584556893883319
            },
            "overall": {
                "Accuracy": 0.35802469135802467
            }
        },
        "culture": {
            "human_sexuality": {
                "Accuracy": 0.35877862595419846
            },
            "sociology": {
                "Accuracy": 0.3482587064676617
            },
            "average": {
                "Accuracy": 0.3535186662109301
            },
            "overall": {
                "Accuracy": 0.35240963855421686
            }
        },
        "economics": {
            "econometrics": {
                "Accuracy": 0.2719298245614035
            },
            "high_school_macroeconomics": {
                "Accuracy": 0.358974358974359
            },
            "high_school_microeconomics": {
                "Accuracy": 0.40756302521008403
            },
            "average": {
                "Accuracy": 0.34615573624861556
            },
            "overall": {
                "Accuracy": 0.3611859838274933
            }
        },
        "geography": {
            "high_school_geography": {
                "Accuracy": 0.4898989898989899
            },
            "average": {
                "Accuracy": 0.4898989898989899
            },
            "overall": {
                "Accuracy": 0.4898989898989899
            }
        },
        "psychology": {
            "high_school_psychology": {
                "Accuracy": 0.363302752293578
            },
            "professional_psychology": {
                "Accuracy": 0.29901960784313725
            },
            "average": {
                "Accuracy": 0.3311611800683576
            },
            "overall": {
                "Accuracy": 0.3292999135695765
            }
        }
    },
    "other (business, health, misc.)": {
        "other": {
            "global_facts": {
                "Accuracy": 0.24
            },
            "miscellaneous": {
                "Accuracy": 0.35887611749680715
            },
            "professional_accounting": {
                "Accuracy": 0.2695035460992908
            },
            "average": {
                "Accuracy": 0.289459887865366
            },
            "overall": {
                "Accuracy": 0.32703862660944205
            }
        },
        "business": {
            "business_ethics": {
                "Accuracy": 0.35
            },
            "management": {
                "Accuracy": 0.4563106796116505
            },
            "marketing": {
                "Accuracy": 0.42735042735042733
            },
            "average": {
                "Accuracy": 0.41122036898735925
            },
            "overall": {
                "Accuracy": 0.41647597254004576
            }
        },
        "health": {
            "anatomy": {
                "Accuracy": 0.3333333333333333
            },
            "clinical_knowledge": {
                "Accuracy": 0.4037735849056604
            },
            "college_medicine": {
                "Accuracy": 0.30057803468208094
            },
            "human_aging": {
                "Accuracy": 0.31390134529147984
            },
            "medical_genetics": {
                "Accuracy": 0.37
            },
            "nutrition": {
                "Accuracy": 0.3006535947712418
            },
            "professional_medicine": {
                "Accuracy": 0.4007352941176471
            },
            "virology": {
                "Accuracy": 0.25903614457831325
            },
            "average": {
                "Accuracy": 0.3352514164599696
            },
            "overall": {
                "Accuracy": 0.3384146341463415
            }
        }
    }
}
