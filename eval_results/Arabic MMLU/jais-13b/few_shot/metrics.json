{
    "STEM": {
        "physics": {
            "astronomy": {
                "Accuracy": 0.29605263157894735
            },
            "college_physics": {
                "Accuracy": 0.20588235294117646
            },
            "conceptual_physics": {
                "Accuracy": 0.4
            },
            "high_school_physics": {
                "Accuracy": 0.2119205298013245
            },
            "average": {
                "Accuracy": 0.2784638785803621
            },
            "overall": {
                "Accuracy": 0.3
            }
        },
        "chemistry": {
            "college_chemistry": {
                "Accuracy": 0.21
            },
            "high_school_chemistry": {
                "Accuracy": 0.2512315270935961
            },
            "average": {
                "Accuracy": 0.23061576354679802
            },
            "overall": {
                "Accuracy": 0.2376237623762376
            }
        },
        "biology": {
            "college_biology": {
                "Accuracy": 0.3263888888888889
            },
            "high_school_biology": {
                "Accuracy": 0.2838709677419355
            },
            "average": {
                "Accuracy": 0.3051299283154122
            },
            "overall": {
                "Accuracy": 0.2973568281938326
            }
        },
        "computer science": {
            "college_computer_science": {
                "Accuracy": 0.3
            },
            "computer_security": {
                "Accuracy": 0.37
            },
            "high_school_computer_science": {
                "Accuracy": 0.27
            },
            "machine_learning": {
                "Accuracy": 0.32142857142857145
            },
            "average": {
                "Accuracy": 0.31535714285714284
            },
            "overall": {
                "Accuracy": 0.3155339805825243
            }
        },
        "math": {
            "abstract_algebra": {
                "Accuracy": 0.25
            },
            "college_mathematics": {
                "Accuracy": 0.28
            },
            "elementary_mathematics": {
                "Accuracy": 0.328042328042328
            },
            "high_school_mathematics": {
                "Accuracy": 0.21851851851851853
            },
            "high_school_statistics": {
                "Accuracy": 0.32407407407407407
            },
            "average": {
                "Accuracy": 0.2801269841269841
            },
            "overall": {
                "Accuracy": 0.287593984962406
            }
        },
        "engineering": {
            "electrical_engineering": {
                "Accuracy": 0.4206896551724138
            },
            "average": {
                "Accuracy": 0.4206896551724138
            },
            "overall": {
                "Accuracy": 0.4206896551724138
            }
        }
    },
    "humanities": {
        "history": {
            "high_school_european_history": {
                "Accuracy": 0.22424242424242424
            },
            "high_school_us_history": {
                "Accuracy": 0.24509803921568626
            },
            "high_school_world_history": {
                "Accuracy": 0.2109704641350211
            },
            "prehistory": {
                "Accuracy": 0.33641975308641975
            },
            "average": {
                "Accuracy": 0.2541826701698878
            },
            "overall": {
                "Accuracy": 0.2645161290322581
            }
        },
        "philosophy": {
            "formal_logic": {
                "Accuracy": 0.19047619047619047
            },
            "logical_fallacies": {
                "Accuracy": 0.26993865030674846
            },
            "moral_disputes": {
                "Accuracy": 0.3670520231213873
            },
            "moral_scenarios": {
                "Accuracy": 0.2849162011173184
            },
            "philosophy": {
                "Accuracy": 0.36977491961414793
            },
            "world_religions": {
                "Accuracy": 0.3508771929824561
            },
            "average": {
                "Accuracy": 0.3055058629363748
            },
            "overall": {
                "Accuracy": 0.3106361829025845
            }
        },
        "law": {
            "international_law": {
                "Accuracy": 0.4462809917355372
            },
            "jurisprudence": {
                "Accuracy": 0.42592592592592593
            },
            "professional_law": {
                "Accuracy": 0.26140808344198174
            },
            "average": {
                "Accuracy": 0.37787166703448155
            },
            "overall": {
                "Accuracy": 0.2841747022121384
            }
        }
    },
    "social sciences": {
        "politics": {
            "high_school_government_and_politics": {
                "Accuracy": 0.32124352331606215
            },
            "public_relations": {
                "Accuracy": 0.33636363636363636
            },
            "security_studies": {
                "Accuracy": 0.4204081632653061
            },
            "us_foreign_policy": {
                "Accuracy": 0.51
            },
            "average": {
                "Accuracy": 0.3970038307362512
            },
            "overall": {
                "Accuracy": 0.3904320987654321
            }
        },
        "culture": {
            "human_sexuality": {
                "Accuracy": 0.35877862595419846
            },
            "sociology": {
                "Accuracy": 0.40298507462686567
            },
            "average": {
                "Accuracy": 0.38088185029053206
            },
            "overall": {
                "Accuracy": 0.3855421686746988
            }
        },
        "economics": {
            "econometrics": {
                "Accuracy": 0.2807017543859649
            },
            "high_school_macroeconomics": {
                "Accuracy": 0.34615384615384615
            },
            "high_school_microeconomics": {
                "Accuracy": 0.3445378151260504
            },
            "average": {
                "Accuracy": 0.32379780522195384
            },
            "overall": {
                "Accuracy": 0.33557951482479786
            }
        },
        "geography": {
            "high_school_geography": {
                "Accuracy": 0.2878787878787879
            },
            "average": {
                "Accuracy": 0.2878787878787879
            },
            "overall": {
                "Accuracy": 0.2878787878787879
            }
        },
        "psychology": {
            "high_school_psychology": {
                "Accuracy": 0.28073394495412846
            },
            "professional_psychology": {
                "Accuracy": 0.3137254901960784
            },
            "average": {
                "Accuracy": 0.2972297175751034
            },
            "overall": {
                "Accuracy": 0.29818496110630943
            }
        }
    },
    "other (business, health, misc.)": {
        "other": {
            "global_facts": {
                "Accuracy": 0.22
            },
            "miscellaneous": {
                "Accuracy": 0.34355044699872284
            },
            "professional_accounting": {
                "Accuracy": 0.24822695035460993
            },
            "average": {
                "Accuracy": 0.27059246578444424
            },
            "overall": {
                "Accuracy": 0.3098712446351931
            }
        },
        "business": {
            "business_ethics": {
                "Accuracy": 0.38
            },
            "management": {
                "Accuracy": 0.34951456310679613
            },
            "marketing": {
                "Accuracy": 0.4358974358974359
            },
            "average": {
                "Accuracy": 0.388470666334744
            },
            "overall": {
                "Accuracy": 0.40274599542334094
            }
        },
        "health": {
            "anatomy": {
                "Accuracy": 0.3037037037037037
            },
            "clinical_knowledge": {
                "Accuracy": 0.39245283018867927
            },
            "college_medicine": {
                "Accuracy": 0.3179190751445087
            },
            "human_aging": {
                "Accuracy": 0.3811659192825112
            },
            "medical_genetics": {
                "Accuracy": 0.35
            },
            "nutrition": {
                "Accuracy": 0.3202614379084967
            },
            "professional_medicine": {
                "Accuracy": 0.3602941176470588
            },
            "virology": {
                "Accuracy": 0.3253012048192771
            },
            "average": {
                "Accuracy": 0.34388728608677943
            },
            "overall": {
                "Accuracy": 0.3475609756097561
            }
        }
    }
}
